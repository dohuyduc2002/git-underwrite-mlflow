{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505b67b6-0e41-448a-a957-4ce0ace67b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe01160-a7be-4357-b3dc-478f06b51299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import (\n",
    "    InputPath,\n",
    "    InputTextFile,\n",
    "    OutputPath,\n",
    "    OutputTextFile,\n",
    "    func_to_container_op,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from typing import NamedTuple\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from constants import NAMESPACE, HOST, NAMESPACE\n",
    "from utils import get_session_cookie, get_or_create_experiment, get_or_create_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f642c28-ab07-402e-b245-35b61a50e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where all the runs belong to the pipeline reside in\n",
    "EXPERIMENT_NAME = \"underwrite-model-boosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2447a73-5444-4249-8bab-a71e1bc2b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first component to download data, train-test split\n",
    "# and then dump all the data for downstream components to use\n",
    "def prepare_data(\n",
    "    url: str,\n",
    "    X_train_path: OutputPath(\"PKL\"),\n",
    "    y_train_path: OutputPath(\"PKL\"),\n",
    "    X_val_path: OutputPath(\"PKL\"),\n",
    "    y_val_path: OutputPath(\"PKL\"),\n",
    "    X_test_path: OutputPath(\"PKL\"),\n",
    "    y_test_path: OutputPath(\"PKL\"),\n",
    "):\n",
    "    import pandas as pd\n",
    "    import wget\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import joblib\n",
    "    import os\n",
    "    import boto3\n",
    "\n",
    "    # Download dataset to local\n",
    "    wget.download(url)\n",
    "\n",
    "    # Create X and y\n",
    "    df = pd.read_csv(\"housing.csv\")\n",
    "    X = df.drop(columns=[\"price\"])\n",
    "    y = df[\"price\"]\n",
    "\n",
    "    # Create train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    # Continue to split train set into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    # Dump data to pkl for downstream components to use\n",
    "    joblib.dump(X_train, X_train_path)\n",
    "    joblib.dump(y_train, y_train_path)\n",
    "    joblib.dump(X_val, X_val_path)\n",
    "    joblib.dump(y_val, y_val_path)\n",
    "    joblib.dump(X_test, X_test_path)\n",
    "    joblib.dump(y_test, y_test_path)\n",
    "\n",
    "\n",
    "# Instead of using create_component_from_func,\n",
    "# you can use this instead\n",
    "prepare_data_op = func_to_container_op(\n",
    "    func=prepare_data,\n",
    "    packages_to_install=[\n",
    "        \"scikit-learn==1.3.2\",\n",
    "        \"joblib==1.3.2\",\n",
    "        \"pandas==2.1.3\",\n",
    "        \"numpy==1.26.2\"\n",
    "        \"wget==3.2\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae438e68-e67a-40d8-b755-cbd3f5eb7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component\n",
    "def download_csv_op(pvc_path: kfp.dsl.OutputPath(str)):\n",
    "    import boto3\n",
    "    import os\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url='http://minio-service.kubeflow.svc.cluster.local:9000',\n",
    "        aws_access_key_id='minio',\n",
    "        aws_secret_access_key='minio123',\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(pvc_path), exist_ok=True)\n",
    "    s3.download_file('sample-data', 'data/application_train.csv', pvc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17bdf7-fd1f-4bd1-955f-9c2455898f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
